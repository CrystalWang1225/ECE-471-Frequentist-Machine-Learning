{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML3 Crystal&Yingzhi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CrystalWang1225/ECE-471-Frequentist-Machine-Learning/blob/main/ML3_Crystal%26Yingzhi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP_XIphcFyCb"
      },
      "source": [
        "Model Assesment and selection\n",
        "Crystal & Yingzhi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycNSrhFizDid"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "from random import *\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "N = 50\n",
        "p = 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJgqC7h0GEJV"
      },
      "source": [
        "# Incorrect Way of Cross-Validation\n",
        "\n",
        "Both incorrect and correct way of cross-validation is from 7.10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOQxHLYwFZMg",
        "outputId": "8c4acb08-3eb6-40ca-d99e-0a2d40befec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The number of simulation we need to run\n",
        "n_simulation = 50\n",
        "# The initialization for the accuracy for each simulation\n",
        "cv_score_wrong = np.zeros((n_simulation,5))\n",
        "for n in range(n_simulation):\n",
        "  # predictor consists of N * p and it's pure Gaussian noise\n",
        "  predictor = np.zeros((N, p))\n",
        "  # labels are random 0s and 1s\n",
        "  labels = np.zeros((N, 1)) \n",
        "  for each in range(N):\n",
        "      labels[each] = randint(0, 1)\n",
        "      predictor[each] = np.random.normal(0, 1, p)\n",
        "  # the initialization of correlations of each predictor\n",
        "  cor = np.zeros((p,1))\n",
        "\n",
        "  for i in range(p):\n",
        "    x = predictor[:, i].reshape(50, 1)\n",
        "    cor[i] = np.corrcoef(x.T, labels.T)[1,0]\n",
        "\n",
        "  # sort the correlation matrix and take the last 100 as the best predictors\n",
        "  sorted = np.sort(cor, axis = 0)\n",
        "  sorted = sorted[4900:]\n",
        "  # the initialization of the indices of the best predictors\n",
        "  indexBest = np.zeros((100,1))\n",
        "  for j in range(100):\n",
        "    for k in range(p):\n",
        "      if cor[k] == sorted[j]:\n",
        "        indexBest[j] = k\n",
        "  index = indexBest.astype(int)\n",
        "  # the initialziation of the best 100 predictor matrix\n",
        "  bestPredictor = np.zeros((50,100))\n",
        "  for i in range(100):\n",
        "    bestPredictor[:,i] = predictor[:,index[i]].ravel()\n",
        "  #using the sci-kit with n neighbors = 1\n",
        "  incorrectNeighbor = KNeighborsClassifier(n_neighbors = 1)\n",
        "  cv_score_wrong[n,:] = cross_val_score(incorrectNeighbor, bestPredictor, labels)\n",
        "\n",
        "# take the average of the accuracy\n",
        "averageFold = sum(cv_score_wrong)/len(cv_score_wrong)\n",
        "accuracyWrong = sum(averageFold)/len(averageFold)\n",
        "\n",
        "print(\"Accuracy using the wrong method: \", accuracyWrong)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using the wrong method:  0.9711999999999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UysLjUEdHjjF"
      },
      "source": [
        "It has demonstrates the overftting behavior of the wrong model.The screening of the prdictors consists of all the samples. Selecting the predictors after all the samples have seen have caused such a huge probelm "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADFs0fjWsEol"
      },
      "source": [
        "# Correct Way of cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZYwjpdIsKzK",
        "outputId": "45f3d307-aec1-4f4c-daab-89a21166a2e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_simulation = 50\n",
        "score_correct = np.zeros((1, n_simulation))\n",
        "for n in range(n_simulation):\n",
        "    predictor_raw = np.zeros((N, p))\n",
        "    predictor = list()\n",
        "    labels = np.zeros((N, 1))\n",
        "    scores = np.zeros((1, 5))\n",
        "    for each in range(N):\n",
        "        labels[each] = randint(0, 1)\n",
        "        predictor_raw[each] = np.random.normal(0, 1, p)\n",
        "    # Split training data into five parts\n",
        "    for i in range(5):\n",
        "        predictor.append(predictor_raw[i*10:(i+1)*10, :])\n",
        "    predictor = np.array(predictor)\n",
        "    # Loop through each part as validation set.\n",
        "    for k in range(5):\n",
        "        validation = predictor[k, :, :]\n",
        "        validation_label = labels[k*10:(k+1)*10, :]\n",
        "        training_indexes = list(range(5))\n",
        "        training_indexes.remove(k)\n",
        "        training_label = np.vstack((labels[:k*10, :], labels[(k+1)*10:, :]))\n",
        "        training = np.vstack(tuple([predictor[j, :, :] for j in training_indexes]))\n",
        "        cor = np.zeros((p, 1))\n",
        "\n",
        "        for i in range(p):\n",
        "            x = training[:, i].reshape(40, 1)\n",
        "            cor[i] = np.corrcoef(x.T, training_label.T)[1, 0]\n",
        "\n",
        "        sorted = np.sort(cor, axis=0)\n",
        "        sorted = sorted[4900:]\n",
        "        index_best = np.zeros((100, 1))\n",
        "        for j in range(100):\n",
        "            for b in range(p):\n",
        "                if cor[b] == sorted[j]:\n",
        "                    index_best[j] = b\n",
        "        index = index_best.astype(int)\n",
        "        best_predictor = np.zeros((40, 100))\n",
        "        best_predictor_val = np.zeros((10, 100))\n",
        "        for i in range(100):\n",
        "            best_predictor[:, i] = training[:, index[i]].ravel()\n",
        "            best_predictor_val[:, i] = validation[:, index[i]].ravel()\n",
        "        # Use multi-variable logistic regression to do classification\n",
        "        clf = LogisticRegression(random_state=0).fit(best_predictor, training_label)\n",
        "        score = clf.score(best_predictor_val, validation_label)\n",
        "        scores[0, k] = score\n",
        "    score_correct[0, n] = np.mean(scores)\n",
        "print(\"Accuracy using the correct way of cross-validation: \", np.mean(score_correct))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9YPLrOTJPKf"
      },
      "source": [
        "The correct method yields an accuracy of 50%, which matches the true error rate."
      ]
    }
  ]
}